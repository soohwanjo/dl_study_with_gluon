{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QA - gluon\n",
    "* http://gluon.mxnet.io/chapter08_computer-vision/visual-question-answer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T01:21:32.366749Z",
     "start_time": "2018-01-29T01:21:31.619264Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kionkim/anaconda3/envs/kion_venv_mxnet/lib/python3.6/site-packages/urllib3/contrib/pyopenssl.py:46: DeprecationWarning: OpenSSL.rand is deprecated - you should use os.urandom instead\n",
      "  import OpenSSL.SSL\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "import mxnet.ndarray as F\n",
    "import mxnet.contrib.ndarray as C\n",
    "import mxnet.gluon as gluon\n",
    "from mxnet.gluon import nn\n",
    "from mxnet import autograd\n",
    "import bisect\n",
    "from IPython.core.display import display, HTML\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "import os\n",
    "from mxnet.test_utils import download\n",
    "import json\n",
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T01:21:34.036916Z",
     "start_time": "2018-01-29T01:21:34.030974Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "ctx = mx.cpu()\n",
    "compute_size = batch_size\n",
    "out_dim = 10000\n",
    "gpus = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In the first model, we will concatenate the image and question features and use multilayer perception(MLP) to predict the answe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T01:21:39.582460Z",
     "start_time": "2018-01-29T01:21:39.543884Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net1(gluon.Block):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Net1, self).__init__(**kwargs)\n",
    "        with self.name_scope():\n",
    "            self.bn = nn.BatchNorm()\n",
    "            self.dropout = nn.Dropout(0.3)\n",
    "            self.fc1 = nn.Dense(8192, activation = 'relu')\n",
    "            self.fc2 = nn.Dense(1000)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = F.L2Normalization(x[0])\n",
    "        x2 = F.L2Normalization(x[1])\n",
    "        z = F.concat(x1, x2, dim = 1)\n",
    "        z = self.fc1(z)\n",
    "        z = self.bn(z)\n",
    "        z = self.dropout(z)\n",
    "        z = self.fc2(z)\n",
    "        return z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T01:21:45.166107Z",
     "start_time": "2018-01-29T01:21:45.146687Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net1(\n",
       "  (bn): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, in_channels=None)\n",
       "  (dropout): Dropout(p = 0.3)\n",
       "  (fc1): Dense(None -> 8192, Activation(relu))\n",
       "  (fc2): Dense(None -> 1000, linear)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net1 = Net1()\n",
    "net1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In the second model, instead of linearly combine the image and text features, we use count sketch to estimate the outer product of the image and question features. It is also named as multimodel compact bilinear pooling(MCB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-29T01:23:32.403492Z",
     "start_time": "2018-01-29T01:23:32.291201Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net2(gluon.Block):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Net2, self).__init__(**kwargs)\n",
    "        with self.name_scope():\n",
    "            slef.bn = nn.BatchNorm()\n",
    "            self.dropout = nn.Dropout(0.3)\n",
    "            self.fc1 = nn.Dense(8192, activation = 'relu')\n",
    "            self.fc2 = nn.Dense(1000)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1 = F.L2Normalization(x[0])\n",
    "        x2 = F.L2Normalization(x[1])\n",
    "        text_ones = F.ones((batch_size/gpus, 2048), ctx = ctx)\n",
    "        img_ones = F.ones((batch_size/gpus, 2048), ctx = ctx)\n",
    "        text_data = F.Concat(x1, text_ones, dim = 1)\n",
    "        image_data = F.Concat(x2, img_ones, dim = 1)\n",
    "        # Initialize hash tables\n",
    "        S1 = F.array(np.random.randint(0, 2, (1, 3072))*2 -1 , ctx = ctx)\n",
    "        H1 = F.array(np.random.randint(0, out_dim(1, 3072))*2 - 1, ctx = ctx)\n",
    "        S2 = F.array(np.random.randint(0, 2, (1, 3072))*2 -1 , ctx = ctx)\n",
    "        H2 = F.array(np.random.randint(0, out_dim(1, 3072))*2 - 1, ctx = ctx)\n",
    "        # Count Sketch\n",
    "        cs1 = C.count_sketch(data = image_data, s = S1, h = H1, name = 'cs1', out_dim = out_dim)\n",
    "        cs2 = C.count_sketch(data = text_data, s = S1, h = H1, name = 'cs1', out_dim = out_dim)\n",
    "        fft1 = C.fft(data = cs1, name = 'fft1', compute_size = compute_size)\n",
    "        ff2 = C.fft(data = cs2, name = 'fft2', compute_size = compute_size)\n",
    "        c = fft1 * fft2 # Elementwise product\n",
    "        ifft1 = C.ifft(data = c, name = 'ifft1', compute_size = compute_size)\n",
    "        # MLP\n",
    "        z = self.fc1(ifft1)\n",
    "        z = self.bn(z)\n",
    "        z = self.dropout(z)\n",
    "        z = self.fc2(z)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-22T22:57:20.085993Z",
     "start_time": "2018-01-22T22:57:19.696268Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VQAtrainIter(mx.io.DataIter):\n",
    "    def __init__(self, img, sentences, answer, batch_size, buckets=None, invalid_label=-1,\n",
    "                 text_name='text', img_name = 'image', label_name='softmax_label', dtype='float32', layout='NTC'):\n",
    "        super(VQAtrainIter, self).__init__()\n",
    "        if not buckets:\n",
    "            buckets = [i for i, j in enumerate(np.bincount([len(s) for s in sentences]))\n",
    "                       if j >= batch_size]\n",
    "        buckets.sort()\n",
    "\n",
    "        ndiscard = 0\n",
    "        self.data = [[] for _ in buckets]\n",
    "        for i in range(len(sentences)):\n",
    "            buck = bisect.bisect_left(buckets, len(sentences[i]))\n",
    "            if buck == len(buckets):\n",
    "                ndiscard += 1\n",
    "                continue\n",
    "            buff = np.full((buckets[buck],), invalid_label, dtype=dtype)\n",
    "            buff[:len(sentences[i])] = sentences[i]\n",
    "            self.data[buck].append(buff)\n",
    "\n",
    "        self.data = [np.asarray(i, dtype=dtype) for i in self.data]\n",
    "        self.answer = answer\n",
    "        self.img = img\n",
    "        print(\"WARNING: discarded %d sentences longer than the largest bucket.\"%ndiscard)\n",
    "\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.buckets = buckets\n",
    "        self.text_name = text_name\n",
    "        self.img_name = img_name\n",
    "        self.label_name = label_name\n",
    "        self.dtype = dtype\n",
    "        self.invalid_label = invalid_label\n",
    "        self.nd_text = []\n",
    "        self.nd_img = []\n",
    "        self.ndlabel = []\n",
    "        self.major_axis = layout.find('N')\n",
    "        self.default_bucket_key = max(buckets)\n",
    "\n",
    "        if self.major_axis == 0:\n",
    "            self.provide_data = [(text_name, (batch_size, self.default_bucket_key)),\n",
    "                                 (img_name, (batch_size, self.default_bucket_key))]\n",
    "            self.provide_label = [(label_name, (batch_size, self.default_bucket_key))]\n",
    "        elif self.major_axis == 1:\n",
    "            self.provide_data = [(text_name, (self.default_bucket_key, batch_size)),\n",
    "                                 (img_name, (self.default_bucket_key, batch_size))]\n",
    "            self.provide_label = [(label_name, (self.default_bucket_key, batch_size))]\n",
    "        else:\n",
    "            raise ValueError(\"Invalid layout %s: Must by NT (batch major) or TN (time major)\")\n",
    "\n",
    "        self.idx = []\n",
    "        for i, buck in enumerate(self.data):\n",
    "            self.idx.extend([(i, j) for j in range(0, len(buck) - batch_size + 1, batch_size)])\n",
    "        self.curr_idx = 0\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.curr_idx = 0\n",
    "        self.nd_text = []\n",
    "        self.nd_img = []\n",
    "        self.ndlabel = []\n",
    "        for buck in self.data:\n",
    "            label = np.empty_like(buck.shape[0])\n",
    "            label = self.answer\n",
    "            self.nd_text.append(mx.ndarray.array(buck, dtype=self.dtype))\n",
    "            self.nd_img.append(mx.ndarray.array(self.img, dtype=self.dtype))\n",
    "            self.ndlabel.append(mx.ndarray.array(label, dtype=self.dtype))\n",
    "\n",
    "    def next(self):\n",
    "        if self.curr_idx == len(self.idx):\n",
    "            raise StopIteration\n",
    "        i, j = self.idx[self.curr_idx]\n",
    "        self.curr_idx += 1\n",
    "\n",
    "        if self.major_axis == 1:\n",
    "            img = self.nd_img[i][j:j + self.batch_size].T\n",
    "            text = self.nd_text[i][j:j + self.batch_size].T\n",
    "            label = self.ndlabel[i][j:j+self.batch_size]\n",
    "        else:\n",
    "            img = self.nd_img[i][j:j + self.batch_size]\n",
    "            text = self.nd_text[i][j:j + self.batch_size]\n",
    "            label = self.ndlabel[i][j:j+self.batch_size]\n",
    "\n",
    "        data = [text, img]\n",
    "        return mx.io.DataBatch(data, [label],\n",
    "                         bucket_key=self.buckets[i],\n",
    "                         provide_data=[(self.text_name, text.shape),(self.img_name, img.shape)],\n",
    "                         provide_label=[(self.label_name, label.shape)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-22T22:49:48.147359Z",
     "start_time": "2018-01-22T22:49:48.140350Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.bincount([1,2,3])\n",
    "a.sort()\n",
    "print(a)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:kion_venv_mxnet]",
   "language": "python",
   "name": "conda-env-kion_venv_mxnet-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
